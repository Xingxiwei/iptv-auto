import requests
import re
import datetime
import time  # æ ¸å¿ƒï¼šç”¨åšŸè¨ˆ Latency (åæ‡‰æ™‚é–“)ï¼Œæ•¸å€¼æ„ˆç´°ä»£è¡¨è½‰å°æ„ˆå¿«
from opencc import OpenCC  # æ ¸å¿ƒï¼šç°¡è½‰ç¹ï¼Œé˜²æ­¢åŒä¸€å€‹å°å› ç‚ºå­—é«”å•é¡Œåˆ†é–‹å…©è¡Œ
from concurrent.futures import ThreadPoolExecutor  # æ ¸å¿ƒï¼šå¤šç·šç¨‹å¼•æ“ï¼Œå°‡æƒæé€Ÿåº¦æå‡ 30 å€

# ã€åˆå§‹åŒ–ã€‘ç¹ç°¡è½‰æ›å™¨ï¼šs2t = Simplified to Traditional
cc = OpenCC('s2t')

# --- 1. ç¶²è·¯è¨‚é–±æº 
SOURCE_URLS = [
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%BE%B3%E9%97%A8202506.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%BE%B3%E9%97%A82023.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%BE%B3%E9%97%A82022-7.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%BE%B3%E9%97%A82022-11.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%B5%B7%E5%A4%96202005.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%B5%B7%E5%A4%99202003.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%B5%B7%E5%A4%96.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/1300%E4%B8%AA%E7%9B%B4%E6%92%AD%E6%BA%90%E5%85%A8%E9%83%A8%E6%9C%89%E6%95%88%E3%80%90%E5%85%A8%E9%83%A84k%E8%80%81%E7%94%B5%E8%84%91%E5%88%AB%E7%94%A8%E3%80%91.m3u8",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/5000%E4%B8%AA%E7%9B%B4%E6%92%AD%E6%BA%90%E5%85%A8%E9%83%A8%E6%9C%89%E6%95%88.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E6%88%91%E7%9A%84%E6%92%AD%E6%94%BE%E6%BA%90.m3u8",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/3100%E4%B8%AA%E5%85%A8%E9%83%A8%E6%9C%89%E6%95%88.m3u8",
    "https://raw.githubusercontent.com/billy21/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%B9%BF%E4%B8%9C%E8%81%94%E9%80%9A.m3u",
    "https://raw.githubusercontent.com/suxuang/myIPTV/refs/heads/main/ipv4.m3u",
    "https://raw.githubusercontent.com/vicjl/myIPTV/refs/heads/main/CNTV.m3u",
    "https://raw.githubusercontent.com/vicjl/myIPTV/refs/heads/main/IPTV-all.m3u",
    "https://raw.githubusercontent.com/Guovin/iptv-api/refs/heads/gd/output/result.m3u",
    "https://raw.githubusercontent.com/Kimentanm/aptv/master/m3u/iptv.m3u",
    "https://raw.githubusercontent.com/yuanzl77/IPTV/main/live.m3u",
    "https://iptv-org.github.io/iptv/index.m3u",
    "https://raw.githubusercontent.com/joevess/IPTV/main/home.m3u8",
    "https://raw.githubusercontent.com/YanG-1989/m3u/main/Gather.m3u",
    "https://raw.githubusercontent.com/iptv-org/iptv/refs/heads/master/streams/hk.m3u",
    "https://raw.githubusercontent.com/Free-TV/IPTV/refs/heads/master/playlists/playlist_hong_kong.m3u8",
    "https://raw.githubusercontent.com/vbskycn/iptv/refs/heads/master/tv/iptv4.m3u",
    "https://epg.pw/test_channels_hong_kong.m3u",
    "https://raw.githubusercontent.com/hujingguang/ChinaIPTV/main/cnTV_AutoUpdate.m3u8",
    "https://raw.githubusercontent.com/MercuryZz/IPTVN/refs/heads/Files/GAT.m3u",
    "https://raw.githubusercontent.com/xiweiwong/iptv/refs/heads/master/iptv.m3u",
    "https://raw.githubusercontent.com/fanmingming/live/main/tv/m3u/index.m3u",
    "https://raw.githubusercontent.com/Mitchll1214/m3u/main/æ¸¯æ¾³å°.m3u",
    "https://raw.githubusercontent.com/fanmingming/live/main/tv/m3u/ipv6.m3u",
    "https://iptv-org.github.io/iptv/countries/hk.m3u",
    "https://raw.githubusercontent.com/YueChan/Live/main/IPTV.m3u",
    "https://raw.githubusercontent.com/YueChan/Live/main/GNTV.m3u",
    "https://raw.githubusercontent.com/Guovin/iptv-api/gd/output/result.m3u",
    "https://raw.githubusercontent.com/ssili126/tv/main/itvlist.m3u",
    "https://raw.githubusercontent.com/Guovin/iptv-api/gd/output/ipv6/result.m3u",
    "https://raw.githubusercontent.com/Guovin/iptv-api/gd/output/ipv4/result.m3u",
    "https://iptv-org.github.io/iptv/countries/tw.m3u",
    "https://raw.githubusercontent.com/melody0709/cmcc_iptv_auto_py/main/ku9.m3u",
    "https://raw.githubusercontent.com/melody0709/cmcc_iptv_auto_py/main/tv.m3u",
    "https://raw.githubusercontent.com/melody0709/cmcc_iptv_auto_py/main/tv2.m3u"
]

# --- 2. æ‰‹å‹•è£œå……æº (ç©©å®šå˜…ç§è— Source) ---
# å‘¢åº¦å¯ä»¥æ”¾ä¸€å•²å””å–º M3U å…¥é¢ï¼Œä½†ä½ ä¸€å®šè¦ç‡å˜…å°
MANUAL_SINGLE_CHANNELS = [
    {"name": "ç¿¡ç¿ å°", "url": "https://HaNoiIPTV.short.gy/Que_huong_HaNoiIPTV-TVB_Fei_Cui_Tai"},
    {"name": "ç¿¡ç¿ å°", "url": "http://php.jdshipin.com/TVOD/iptv.php?id=fct2"},
    {"name": "å¤§ç£å€è¡›è¦–", "url": "http://183.11.239.36:808/hls/132/index.m3u8"}
]

# --- 3. é—œéµå­—éæ¿¾ (å‘½ä¸­å…ˆæœƒå…¥æœ€çµ‚ M3U) ---
KEYWORDS = ["ViuTV", "HOY", "RTHK", "Jade", "Pearl", "J2", "J5", "Now", "ç„¡ç·š", "æœ‰ç·š", "ç¿¡ç¿ ", "æ˜ç ", "æ¸¯å°", "å»£æ±", "ç æ±Ÿ", "å»£å·", "å¤§ç£å€", "é³³å‡°", "æ°‘è¦–", "æ±æ£®", "ä¸‰ç«‹", "ä¸­è¦–", "å…¬è¦–", "TVBS", "ç·¯ä¾†", "å¹´ä»£", "ä¸­å¤©", "éå‡¡", "æ¾³è¦–", "æ¾³é–€", "TDM", "æ¾³äº"]

# --- 4. é»‘åå–® (åŒ…å«å‘¢å•²å­—çœ¼å˜…å°æœƒè¢«ç›´æ¥è¸¢èµ°) ---
BLOCK_KEYWORDS = ["FOX", "UHD", "8K", "æµ™æ±Ÿ", "æ­å·", "æ·±åœ³", "CCTV", "å»¶æ—¶", "æ¸¬è©¦"]

# --- 5. æ’åºå„ªå…ˆç´š (è¶Šæ’å‰é¢ä»£è¡¨æ¬Šé‡è¶Šé«˜) ---
ORDER_KEYWORDS = ["å»£æ±", "ç æ±Ÿ", "å»£å·", "å»£æ±è¡›è¦–", "å¤§ç£å€", "å—æ–¹", "æ¸¯å°é›»è¦–", "ç¿¡ç¿ ", "ç„¡ç·šæ–°è", "æ˜ç ", "J2", "J5", "è²¡ç¶“", "Viu", "HOY", "å¥‡å¦™", "æœ‰ç·š", "Now", "æ°‘è¦–", "ä¸­è¦–", "è¯è¦–", "å…¬è¦–", "TVBS", "ä¸‰ç«‹", "æ±æ£®", "å¹´ä»£", "å£¹é›»è¦–", "éå‡¡", "ä¸­å¤©", "ç·¯ä¾†", "æ¾³è¦–", "æ¾³é–€", "TDM", "æ¾³äº"]

# --- 6. å®˜æ–¹å›ºå®ˆæº (å””æ´—æ¸¬é€Ÿï¼Œç›´æ¥å¡å…¥å») ---
STATIC_CHANNELS = [
    {"name": "æ¸¯å°é›»è¦–31 (å®˜æ–¹)", "url": "https://rthklive1-lh.akamaihd.net/i/rthk31_1@167495/index_2052_av-b.m3u8", "speed": 10}, 
    {"name": "æ¸¯å°é›»è¦–32 (å®˜æ–¹)", "url": "https://rthklive2-lh.akamaihd.net/i/rthk32_1@168450/index_2052_av-b.m3u8", "speed": 10}
]

# --- æ ¸å¿ƒé‚è¼¯å€ ---

# è¨­ç½®å½è£ç€è¦½å™¨é ­éƒ¨ï¼Œå¢åŠ æˆåŠŸç‡
COMMON_HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}

def check_url(item):
    """
    ã€å–®ä¸€é€£çµæ¸¬é€Ÿå‡½æ•¸ã€‘
    1. ç´€éŒ„ç™¼å‡ºè«‹æ±‚å˜…æ™‚é–“ã€‚
    2. ä½¿ç”¨ requests.get å˜—è©¦é€£ç·šï¼Œtimeout=2 ç§’ (é˜²æ­¢å¡æ­»)ã€‚
    3. stream=True åªç²å–å›æ‡‰é ­ (Headers)ï¼Œä¸ä¸‹è¼‰å…§å®¹ä»¥ç¯€çœæµé‡åŒæ™‚é–“ã€‚
    """
    try:
        start_time = time.time()
        response = requests.get(item['url'], timeout=2, headers=COMMON_HEADERS, stream=True)
        if response.status_code == 200:
            # æ¯«ç§’æ•¸ = (ç•¶å‰æ™‚é–“ - é–‹å§‹æ™‚é–“) * 1000
            item['speed'] = int((time.time() - start_time) * 1000)
            response.close()
            return item
    except:
        pass  # ä»»ä½•é€£ç·šéŒ¯èª¤ç›´æ¥å¿½ç•¥ï¼Œè¿”å› None
    return None

def fetch_and_parse():
    """
    ã€ä¸»ç¨‹åºé‚è¼¯ã€‘å…¨æƒæç›²æ¸¬æ¨¡å¼
    """
    all_valid_channels = []
    report_data = [] # ç”¨åšŸå¯«å…¥ source_report.txt å˜…å…§å®¹
    seen_urls = set() # å»é‡ (åŒä¸€æ¢ Link å””æ¸¬å…©æ¬¡)
    
    print("ğŸš€ å•Ÿå‹• 30 ç·šç¨‹ä¸¦ç™¼å…¨æƒæ...", flush=True)
    
    for index, source in enumerate(SOURCE_URLS):
        print(f"\nğŸ“¡ [{index+1}/{len(SOURCE_URLS)}] è®€å– M3U: {source}", flush=True)
        is_taiwan_source = "tw.m3u" in source.lower()
        all_found_raw_data = [] # å„²å­˜å‘¢å€‹æºæµåˆ°å˜…æ‰€æœ‰å°ååŒ Link
        
        try:
            # ä¸‹è¼‰ M3U å…§å®¹
            r = requests.get(source, timeout=15, headers=COMMON_HEADERS)
            r.encoding = 'utf-8'
            if r.status_code != 200:
                report_data.append(f"ä¾†æº: {source}\nç‹€æ…‹: âŒ HTTP éŒ¯èª¤ {r.status_code}\n{'-'*50}")
                continue
            
            lines = r.text.split('\n')
            current_name = ""
            for line in lines:
                line = line.strip()
                if line.startswith("#EXTINF"):
                    # æå–å°åä¸¦ç°¡è½‰ç¹
                    if ',' in line:
                        raw_name = line.split(',')[-1].strip()
                        current_name = cc.convert(raw_name).replace('è‡º', 'å°')
                elif line.startswith("http") and current_name:
                    # æ ¼å¼éæ¿¾ï¼šå‰”é™¤ä¸€å•²å¥‡æ€ªå˜… M3U åˆ†é¡æ¨™ç±¤
                    if "[" in line and "]" in line: continue
                    all_found_raw_data.append({"name": current_name, "url": line})
                    current_name = ""

            if not all_found_raw_data:
                report_data.append(f"ä¾†æº: {source}\nç‹€æ…‹: âšª ç©ºæº\n{'-'*50}")
                continue

            # --- æ ¸å¿ƒæ”¹å‹•ï¼šå¤šç·šç¨‹ç›²æ¸¬ (ThreadPoolExecutor) ---
            # é»è§£ç”¨ 30ï¼Ÿå› ç‚ºå¯ä»¥åŒæ™‚æ¸¬ 30 æ¢ Linkï¼Œé€Ÿåº¦æ¯”å–®ç·šç¨‹å¿« 30 å€ï¼
            print(f"    â³ ç›²æ¸¬é–‹å§‹ ({len(all_found_raw_data)} æ¢é€£çµ)...", end="", flush=True)
            with ThreadPoolExecutor(max_workers=30) as executor:
                # æŠŠä»»å‹™åˆ†ç™¼ä¿¾ 30 å€‹å·¥ä»”ä¸€é½Šåš
                results = list(executor.map(check_url, all_found_raw_data))
            
            # éæ¿¾å‡ºæ´»ç”Ÿç”Ÿå˜…é€£çµ
            valid_this_source = [r for r in results if r is not None]
            matched_this_source = []
            unmatched_but_alive = []
            
            for item in valid_this_source:
                # æª¢æŸ¥é—œéµå­—åŒé»‘åå–®
                is_match = any(k.lower() in item['name'].lower() for k in KEYWORDS)
                is_blocked = any(b.lower() in item['name'].lower() for b in BLOCK_KEYWORDS)
                
                if (is_match or is_taiwan_source) and not is_blocked:
                    if item['url'] not in seen_urls:
                        matched_this_source.append(item)
                        all_valid_channels.append(item)
                        seen_urls.add(item['url'])
                else:
                    # å‘¢å•²å°±ä¿‚é€šå’—ä½†ä½ å†‡å¯« Keyword å˜…ã€Œæ¼ç¶²ä¹‹é­šã€
                    unmatched_but_alive.append(f"{item['name']} ({item['speed']}ms)")

            # æº–å‚™å¥åº·åº¦å ±å‘Š
            report_info = f"ä¾†æº: {source}\n"
            report_info += f"ç‹€æ…‹: âœ… å‘½ä¸­ {len(matched_this_source)} / ç¸½æ´»éˆ {len(valid_this_source)}\n"
            if unmatched_but_alive:
                report_info += f"æ¼ç¶²ä¹‹é­š: {', '.join(unmatched_but_alive)}\n"
            report_info += f"{'-'*50}"
            report_data.append(report_info)
            
            print(f"\r    âœ… å®Œæˆï¼šç™¼ç¾ {len(valid_this_source)} å€‹æ´»éˆ (å…¶ä¸­ {len(matched_this_source)} å€‹ç¬¦åˆé—œéµå­—)")

        except Exception as e:
            report_data.append(f"ä¾†æº: {source}\nç‹€æ…‹: âŒ ä¸‹è¼‰å ±éŒ¯ ({str(e)})\n{'-'*50}")
            print(f"\r    âŒ å ±éŒ¯: {e}")

    # å¯«å…¥å ±å‘Š
    with open("source_report.txt", "w", encoding="utf-8") as f:
        f.write(f"IPTV å…¨æƒæå¥åº·åº¦å ±å‘Š\nç”Ÿæˆæ—¥æœŸ: {datetime.datetime.now()}\n{'='*50}\n\n")
        f.write("\n".join(report_data))
            
    return all_valid_channels

def get_sort_key(item):
    """
    ã€æ’åºä¹‹é­‚ã€‘æ±ºå®šé‚Šå€‹å°å–º M3U æ’ç¬¬ä¸€
    æ¬Šé‡è¨ˆç®—ï¼šåˆ†çµ„æ¬Šé‡ + é—œéµå­—ç´¢å¼• + é€Ÿåº¦å¾®èª¿
    """
    name = item["name"]
    speed = item.get('speed', 9999)

    # 1. å¤§åˆ†çµ„ (ç™¾ä½æ•¸)
    if any(x in name for x in ["å»£å·", "å»£æ±", "ç æ±Ÿ", "å¤§ç£å€", "å—æ–¹"]): gp = 100
    elif any(x in name for x in ["ç¿¡ç¿ ", "ç„¡ç·š", "æ˜ç ", "æ¸¯å°", "RTHK", "viu", "HOY", "å¥‡å¦™", "æœ‰ç·š", "Now", "J2", "J5"]): gp = 200
    elif any(x in name for x in ["æ°‘è¦–", "ä¸­è¦–", "è¯è¦–", "å…¬è¦–", "TVBS", "ä¸‰ç«‹", "æ±æ£®", "å¹´ä»£", "ç·¯ä¾†", "ä¸­å¤©", "éå‡¡"]): gp = 300
    elif any(x in name for x in ["æ¾³é–€", "æ¾³è¦–", "æ¾³äº", "TDM"]): gp = 400
    else: gp = 500

    # 2. é »é“å„ªå…ˆç´š (åä½æ•¸)
    kp = 99
    for i, k in enumerate(ORDER_KEYWORDS):
        if k.lower() in name.lower():
            kp = i
            break
    
    # 3. é€Ÿåº¦å¾®èª¿ (å°æ•¸é»å¾Œä½) - æ•¸å€¼æ„ˆç´°æ’æ„ˆå‰
    return gp + kp + (speed / 1000000)

def generate_m3u(valid_channels):
    """
    ã€æœ€çµ‚ç”Ÿæˆã€‘å°‡è³‡æ–™æ•´ç†æˆ M3U æ¨™æº–æ ¼å¼
    """
    # çµåˆéœæ…‹æºåŒçˆ¬è¿”åšŸå˜…æº
    final_list = list(STATIC_CHANNELS) + valid_channels
    # ä½¿ç”¨ get_sort_key é€²è¡Œå‡åºæ’åº
    final_list.sort(key=get_sort_key)

    content = '#EXTM3U x-tvg-url="https://epg.112114.xyz/pp.xml"\n'
    content += f'# Update: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n'

    # åˆ†çµ„é‚è¼¯
    groups = ["å»£æ±/å»£å·", "é¦™æ¸¯", "å°ç£", "æ¾³é–€", "å…¶ä»–"]
    for current_group in groups:
        for item in final_list:
            name, speed = item["name"], item.get('speed', 0)
            # å†æ¬¡åˆ¤æ–·åˆ†çµ„æ¨™ç±¤ä»¥ä¾¿å¯«å…¥ group-title
            if any(x in name for x in ["æ¾³é–€", "æ¾³è¦–", "æ¾³äº", "TDM"]): ig = "æ¾³é–€"
            elif any(x in name for x in ["æ°‘è¦–", "ä¸­è¦–", "è¯è¦–", "å…¬è¦–", "TVBS", "ä¸‰ç«‹", "æ±æ£®", "å¹´ä»£", "ç·¯ä¾†", "ä¸­å¤©", "éå‡¡"]): ig = "å°ç£"
            elif any(x in name for x in ["å»£å·", "å»£æ±", "ç æ±Ÿ", "å¤§ç£å€", "å—æ–¹"]): ig = "å»£æ±/å»£å·"
            elif any(x in name for x in ["ç¿¡ç¿ ", "ç„¡ç·š", "æ˜ç ", "æ¸¯å°", "RTHK", "viu", "HOY", "å¥‡å¦™", "æœ‰ç·š", "Now", "J2", "J5"]): ig = "é¦™æ¸¯"
            else: ig = "å…¶ä»–"

            if ig == current_group:
                # å¯«å…¥ M3U æ ¼å¼è¡Œï¼Œæ¨™è¨»é€Ÿåº¦æ–¹ä¾¿é™¤éŒ¯
                content += f'#EXTINF:-1 group-title="{ig}" logo="https://epg.112114.xyz/logo/{name}.png",{name} ({speed}ms)\n{item["url"]}\n'

    with open("hk_live.m3u", "w", encoding="utf-8") as f:
        f.write(content)
    print(f"\nğŸ‰ å¤§åŠŸå‘Šæˆï¼å…±æœ‰ {len(final_list)} å€‹é »é“ï¼Œæª”æ¡ˆå„²å­˜ç‚º: hk_live.m3u")

if __name__ == "__main__":
    # åŸ·è¡Œæµç¨‹ï¼š1. çˆ¬èŸ²æ¸¬é€Ÿ -> 2. æ³¨å…¥æ‰‹å‹•æº -> 3. ç”Ÿæˆæª”æ¡ˆ
    live_channels = fetch_and_parse()
    
    print(f"\nğŸ“¦ æ­£åœ¨æª¢æŸ¥æ‰‹å‹•è£œå……æº...", flush=True)
    existing_urls = {c['url'] for c in live_channels}
    for item in MANUAL_SINGLE_CHANNELS:
        item['name'] = cc.convert(item['name']).replace('è‡º', 'å°')
        if item['url'] not in existing_urls:
            checked = check_url(item)
            if checked:
                live_channels.append(checked)
                print(f"    [+] æ‰‹å‹•æºæ³¨å…¥æˆåŠŸ: {item['name']} ({checked.get('speed')}ms)")
    
    generate_m3u(live_channels)
