import requests
import re
import datetime
import time  # å¿…é ˆåŒ¯å…¥ï¼Œç”¨åšŸè¨ˆç®—ç”± Request é–‹å§‹åˆ° Response å®Œç•¢å˜…æ™‚é–“å·® (Latency)
from opencc import OpenCC
from concurrent.futures import ThreadPoolExecutor

# ã€åˆå§‹åŒ–ã€‘ç¹ç°¡è½‰æ›å™¨ï¼šå°‡æ‰€æœ‰æŠ“å–åˆ°å˜…ç°¡é«”é »é“åè½‰åšç¹é«”ï¼Œè²»äº‹åŒä¸€å€‹å°å› ç‚ºç¹ç°¡å•é¡Œåˆ†é–‹å…©è¡Œ
cc = OpenCC('s2t')

# --- è¨­å®šå€ ---
# 1. ç¶²è·¯è¨‚é–±æºåˆ—è¡¨ï¼šç¨‹å¼æœƒé€å€‹è®€å–å‘¢å•²ç¶²å€å…¥é¢å˜… m3u å…§å®¹
SOURCE_URLS = [
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%BE%B3%E9%97%A8202506.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%BE%B3%E9%97%A82023.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%BE%B3%E9%97%A82022-7.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%BE%B3%E9%97%A82022-11.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%B5%B7%E5%A4%96202005.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%B5%B7%E5%A4%96202003.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%B5%B7%E5%A4%96.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/1300%E4%B8%AA%E7%9B%B4%E6%92%AD%E6%BA%90%E5%85%A8%E9%83%A8%E6%9C%89%E6%95%88%E3%80%90%E5%85%A8%E9%83%A84k%E8%80%81%E7%94%B5%E8%84%91%E5%88%AB%E7%94%A8%E3%80%91.m3u8",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/5000%E4%B8%AA%E7%9B%B4%E6%92%AD%E6%BA%90%E5%85%A8%E9%83%A8%E6%9C%89%E6%95%88.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E6%88%91%E7%9A%84%E6%92%AD%E6%94%BE%E6%BA%90.m3u8",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/3100%E4%B8%AA%E5%85%A8%E9%83%A8%E6%9C%89%E6%95%88.m3u8",
    "https://raw.githubusercontent.com/billy21/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%B9%BF%E4%B8%9C%E8%81%94%E9%80%9A.m3u",
    "https://raw.githubusercontent.com/suxuang/myIPTV/refs/heads/main/ipv4.m3u",
    "https://raw.githubusercontent.com/vicjl/myIPTV/refs/heads/main/CNTV.m3u",
    "https://raw.githubusercontent.com/vicjl/myIPTV/refs/heads/main/IPTV-all.m3u",
    "https://raw.githubusercontent.com/Guovin/iptv-api/refs/heads/gd/output/result.m3u",
    "https://raw.githubusercontent.com/Kimentanm/aptv/master/m3u/iptv.m3u",
    "https://raw.githubusercontent.com/yuanzl77/IPTV/main/live.m3u",
    "https://iptv-org.github.io/iptv/index.m3u",
    "https://raw.githubusercontent.com/joevess/IPTV/main/home.m3u8",
    "https://raw.githubusercontent.com/YanG-1989/m3u/main/Gather.m3u",
    "https://raw.githubusercontent.com/iptv-org/iptv/refs/heads/master/streams/hk.m3u",
    "https://raw.githubusercontent.com/Free-TV/IPTV/refs/heads/master/playlists/playlist_hong_kong.m3u8",
    "https://raw.githubusercontent.com/vbskycn/iptv/refs/heads/master/tv/iptv4.m3u",
    "https://epg.pw/test_channels_hong_kong.m3u",
    "https://raw.githubusercontent.com/hujingguang/ChinaIPTV/main/cnTV_AutoUpdate.m3u8",
    "https://raw.githubusercontent.com/MercuryZz/IPTVN/refs/heads/Files/GAT.m3u",
    "https://raw.githubusercontent.com/xiweiwong/iptv/refs/heads/master/iptv.m3u",
    "https://raw.githubusercontent.com/fanmingming/live/main/tv/m3u/index.m3u",
    "https://raw.githubusercontent.com/Mitchll1214/m3u/main/æ¸¯æ¾³å°.m3u",
    "https://raw.githubusercontent.com/fanmingming/live/main/tv/m3u/ipv6.m3u",
    "https://iptv-org.github.io/iptv/countries/hk.m3u",
    "https://raw.githubusercontent.com/YueChan/Live/main/IPTV.m3u",
    "https://raw.githubusercontent.com/YueChan/Live/main/GNTV.m3u",
    "https://raw.githubusercontent.com/Guovin/iptv-api/gd/output/result.m3u",
    "https://raw.githubusercontent.com/ssili126/tv/main/itvlist.m3u",
    "https://raw.githubusercontent.com/Guovin/iptv-api/gd/output/ipv6/result.m3u",
    "https://raw.githubusercontent.com/Guovin/iptv-api/gd/output/ipv4/result.m3u",
    "https://iptv-org.github.io/iptv/countries/tw.m3u",
    "https://raw.githubusercontent.com/melody0709/cmcc_iptv_auto_py/main/ku9.m3u",
    "https://raw.githubusercontent.com/melody0709/cmcc_iptv_auto_py/main/tv.m3u",
    "https://raw.githubusercontent.com/melody0709/cmcc_iptv_auto_py/main/tv2.m3u"
]

# 2. æ‰‹å‹•è£œå……æºï¼šå¦‚æœçˆ¬å””åˆ°å˜…å°ï¼Œå–ºå‘¢åº¦å¼·åˆ¶åŠ å…¥ (ä¾‹å¦‚ä¸€å•²ç©©å®šå˜…å€‹äººæº)
MANUAL_SINGLE_CHANNELS = [
    {"name": "ç¿¡ç¿ å°", "url": "https://HaNoiIPTV.short.gy/Que_huong_HaNoiIPTV-TVB_Fei_Cui_Tai"},
    {"name": "ç¿¡ç¿ å°", "url": "http://php.jdshipin.com/TVOD/iptv.php?id=fct2"},
    {"name": "å¤§ç£å€è¡›è¦–", "url": "http://183.11.239.36:808/hls/132/index.m3u8"}
]

# 3. é—œéµå­—éæ¿¾ï¼šåªæœ‰é »é“ååŒ…å«å‘¢å•²å­—çœ¼å˜…å…ˆæœƒè¢«æ‰å‡ºåšŸ
KEYWORDS = ["ViuTV", "HOY", "RTHK", "Jade", "Pearl", "J2", "J5", "Now", "æ— çº¿", "ç„¡ç·š", "æœ‰çº¿",
            "æœ‰ç·š", "ç¿¡ç¿ ", "æ˜ç ", "æ¸¯å°", "å»£æ±", "ç æ±Ÿ", "å¹¿å·", "å»£å·", "å¤§ç£å€","é³³å‡°", 
            "å‡¤å‡°", "æ°‘è¦–", "æ±æ£®", "ä¸‰ç«‹", "ä¸­è¦–", "å…¬è¦–", "TVBS", "ç·¯ä¾†", "å¹´ä»£", 
            "ä¸­å¤©", "éå‡¡", "æ¾³è¦–", "æ¾³é–€", "TDM", "æ¾³äº"]

# 4. é»‘åå–®ï¼šå°±ç®—ç¬¦åˆé—œéµå­—ï¼Œä½†åŒ…å«å‘¢å•²å­—çœ¼å°±å””è¦ (ä¾‹å¦‚é‡è¤‡å˜…æ¸¬è©¦é »é“)
BLOCK_KEYWORDS = ["FOX", "UHD", "8K", "æµ™æ±Ÿ", "æ­å·", "æ·±åœ³", "CCTV", "å»¶æ—¶", "æ¸¬è©¦"]

# 5. æ’åºå„ªå…ˆç´šï¼šæ±ºå®šå–ºåŒä¸€å€‹åˆ†çµ„å…¥é¢ï¼Œé‚Šå€‹å°æ’å–ºæœ€é ‚ (æ’å–ºè¶Šå‰é¢è¶Šå„ªå…ˆ)
ORDER_KEYWORDS = ["å»£æ±", "ç æ±Ÿ", "å»£å·", "å»£æ±è¡›è¦–", "å¤§ç£å€", "å—æ–¹", "æ¸¯å°é›»è¦–", "ç¿¡ç¿ ", "ç„¡ç·šæ–°è", 
                  "æ˜ç ", "J2", "J5", "è²¡ç¶“", "Viu", "HOY", "å¥‡å¦™", "æœ‰ç·š", "Now", "æ°‘è¦–", "ä¸­è¦–", 
                  "è¯è¦–", "å…¬è¦–", "TVBS", "ä¸‰ç«‹", "æ±æ£®", "å¹´ä»£", "å£¹é›»è¦–", "éå‡¡", "ä¸­å¤©", "ç·¯ä¾†", 
                  "æ¾³è¦–", "æ¾³é–€", "TDM", "æ¾³äº"]

# 6. å®˜æ–¹æˆ–å›ºå®šæºï¼šå””æ´—çˆ¬ã€ç›´æ¥å¡å…¥å»å˜… Link
STATIC_CHANNELS = [
    {"name": "æ¸¯å°é›»è¦–31 (å®˜æ–¹)", "url": "https://rthklive1-lh.akamaihd.net/i/rthk31_1@167495/index_2052_av-b.m3u8", "speed": 10}, 
    {"name": "æ¸¯å°é›»è¦–32 (å®˜æ–¹)", "url": "https://rthklive2-lh.akamaihd.net/i/rthk32_1@168450/index_2052_av-b.m3u8", "speed": 10}
]

# --- æ ¸å¿ƒé‚è¼¯å€ ---

COMMON_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

def check_url(item):
    """
    ã€åŠŸèƒ½ã€‘æ¸¬é€Ÿå™¨ï¼šæª¢æŸ¥ç¶²å€é–‹å””é–‹åˆ°ï¼Œä¸¦è¨˜éŒ„åæ‡‰æ™‚é–“ (Latency)
    - timeout=2: å¦‚æœ 2 ç§’éƒ½é€£å””åˆ°ï¼Œå°±ç•¶ä½¢æ­»å’—ï¼Œè²»äº‹è€äººå®¶ç­‰å¤ªè€ã€‚
    - stream=True: å””æ´—ä¸‹è¼‰æˆå€‹å½±ç‰‡ï¼Œåªè¦é€£é€šå’—æ”åˆ° Header å°±åœï¼Œå’æ¨£æ¸¬é€Ÿå…ˆå¿«ã€‚
    """
    url = item['url']
    headers = COMMON_HEADERS.copy()
    headers['Referer'] = url # æœ‰å•²æºæœƒ Check ä¾†æºç¶²å€ï¼ŒåŠ å€‹ Referer ç©©é™£å•²
    try:
        start_time = time.time()
        response = requests.get(url, timeout=2, headers=headers, stream=True)
        if response.status_code == 200:
            # æ¯«ç§’æ•¸ = (ä¾å®¶æ™‚é–“ - é–‹å§‹æ™‚é–“) * 1000
            item['speed'] = int((time.time() - start_time) * 1000)
            response.close()
            return item
    except: 
        pass
    return None

def fetch_and_parse():
    """
    ã€åŠŸèƒ½ã€‘ä¸»çˆ¬èŸ²é‚è¼¯ï¼šçˆ¬å–æ‰€æœ‰ä¾†æºï¼Œéæ¿¾é—œéµå­—ï¼Œä¸¦ç”Ÿæˆã€Œå¥åº·åº¦åˆ†æå ±å‘Šã€
    - äº®é»ï¼šå¦‚æœæºå…¥é¢å†‡ä½ è¦å˜…å°ï¼Œæœƒåˆ—å‡ºã€Œå…§å®¹æ¨£æœ¬ã€ï¼Œç­‰ä½ çŸ¥é“ä½¿å””ä½¿åŠ  Keywordã€‚
    """
    all_valid_channels = []
    report_data = [] # ç”¨åšŸå„²å­˜æ¯ä¸€ä»½ Source å˜…ç‹€æ…‹ï¼Œæœ€å¾Œå¯«å…¥ source_report.txt
    seen_urls = set() # ç”¨åšŸå»é‡ (Duplicate Removal)ï¼ŒåŒä¸€å€‹ URL å””æ´—æƒå…©æ¬¡
    
    print("ğŸš€ ä»»å‹™é–‹å§‹ï¼æ­£åœ¨å³æ™‚æŠ“å–èˆ‡æ¸¬é€Ÿ...", flush=True)
    
    for index, source in enumerate(SOURCE_URLS):
        print(f"\nğŸ“¡ [{index+1}/{len(SOURCE_URLS)}] æ­£åœ¨è®€å–: {source}", flush=True)
        # é‡å°å°ç£å°ˆç”¨æºåšç‰¹åˆ¥è™•ç† (å°±ç®—åå””å¤¾ Keyword éƒ½æ‰ï¼Œå› ç‚ºå°ç£æºé€šå¸¸æ¯”è¼ƒé›œ)
        is_taiwan_source = "tw.m3u" in source.lower()
        current_candidates = []
        all_found_names = [] # å„²å­˜å‘¢å€‹ Source å…¥é¢æ‰€æœ‰æµåˆ°å˜…å°å (ç„¡è«–å¤¾å””å¤¾ Keyword)
        
        try:
            r = requests.get(source, timeout=15, headers=COMMON_HEADERS)
            r.encoding = 'utf-8'
            if r.status_code != 200: 
                report_data.append(f"ä¾†æº: {source}\nç‹€æ…‹: âŒ ç„¡æ³•å­˜å– (HTTP {r.status_code})\n{'-'*50}")
                continue
            
            lines = r.text.split('\n')
            current_name = ""
            for line in lines:
                line = line.strip()
                if not line: continue
                # M3U æ ¼å¼ï¼š#EXTINF å‘¢è¡Œä¿‚åï¼Œä¸‹ä¸€è¡Œä¿‚ URL
                if line.startswith("#EXTINF"):
                    if ',' in line:
                        raw_name = line.split(',')[-1].strip()
                        # ç¹é«”åŒ–é »é“åï¼Œä¸¦çµ±ä¸€å°‡ã€Œè‡ºã€è½‰åšã€Œå°ã€
                        current_name = cc.convert(raw_name).replace('è‡º', 'å°')
                        all_found_names.append(current_name)
                elif line.startswith("http") and current_name:
                    # 1. æ’é™¤ä¸€å•²å¥‡æ€ªå˜…å»£å‘Šæˆ–éå½±ç‰‡é€£çµ
                    if "[" in line and "]" in line: continue
                    # 2. æª¢æŸ¥é»‘åå–®
                    if any(b.lower() in current_name.lower() for b in BLOCK_KEYWORDS): continue
                    
                    # 3. æª¢æŸ¥é—œéµå­—å‘½ä¸­
                    is_match = any(cc.convert(k).replace('è‡º', 'å°').lower() in current_name.lower() for k in KEYWORDS)
                    
                    # 4. å¦‚æœä¸­ Keyword å…¼æœªè¦‹éå‘¢æ¢ Linkï¼Œå°±åŠ å…¥ã€Œå¾…æ¸¬åå–®ã€
                    if (is_match or is_taiwan_source) and line not in seen_urls:
                        current_candidates.append({"name": current_name, "url": line})
                        seen_urls.add(line)
                    current_name = ""
            
            # --- å°ã€Œå¾…æ¸¬åå–®ã€é€²è¡Œå¤šç·šç¨‹ä¸¦ç™¼æ¸¬é€Ÿ (æé«˜é€Ÿåº¦) ---
# --- è™•ç†æª¢æ¸¬èˆ‡å ±å‘Š ---
            if current_candidates:
                # (å‘¢éƒ¨åˆ†ä¿‚è™•ç†æœ‰å‘½ä¸­é—œéµå­—å˜…é‚è¼¯ï¼Œä¿æŒä¸è®Š)
                total_found = len(current_candidates)
                print(f"    ğŸ“¥ å‘½ä¸­é—œéµå­— {total_found} æ¢ï¼Œå•Ÿå‹• 20 ç·šç¨‹æ¸¬é€Ÿ...", end="", flush=True)
                with ThreadPoolExecutor(max_workers=20) as executor:
                    results = list(executor.map(check_url, current_candidates))
                
                valid_ones = [r for r in results if r is not None]
                count_valid = len(valid_ones)
                all_valid_channels.extend(valid_ones)
                
                health = f"âœ… æœ‰æ•ˆ (æ´»éˆ {count_valid})" if count_valid > 0 else "âš ï¸ é€£çµå¤±æ•ˆ (æµåˆ°é—œéµå­—ä½†å…¨æ­»)"
                report_data.append(f"ä¾†æº: {source}\nç‹€æ…‹: {health} | å‘½ä¸­æ•¸: {total_found}\n{'-'*50}")
                print(f"\r    âœ… å®Œæˆï¼š{count_valid} æ¢å¯ç”¨...")
            else:
                # ã€é‡é»æ›´æ–°ã€‘ç•¶å†‡ç¬¦åˆé—œéµå­—æ™‚ï¼Œåˆ—å‡ºè©²æºã€Œæ‰€æœ‰ã€é »é“åï¼Œä¸å†çœç•¥
                # 1. ä½¿ç”¨ set() å»é™¤é‡è¤‡åç¨±
                # 2. ä½¿ç”¨ sorted() æŒ‰åç¨±æ’åºï¼Œæ–¹ä¾¿ä½ é–±è®€
                all_names_str = ", ".join(sorted(list(set(all_found_names))))
                
                health = "âšª ç•¥é (æ­¤æºå†‡ä½ è¨­å®šå˜…é—œéµå­—é »é“)"
                # å°‡æ‰€æœ‰é »é“åå®Œæ•´å¯«å…¥å ±å‘Š
                report_data.append(f"ä¾†æº: {source}\nç‹€æ…‹: {health}\næ‰€æœ‰é »é“æ¸…å–®: {all_names_str}\n{'-'*50}")
                
                # çµ‚ç«¯æ©Ÿ (Console) ä¾ç„¶é¡¯ç¤ºç°¡çŸ­ç‰ˆæœ¬ï¼Œè²»äº‹æ´—æ™’ä½ å€‹ Screen
                print(f"    âšª ç•¥é (å·²å°‡ {len(set(all_found_names))} å€‹é »é“åå¯«å…¥å ±å‘Š)")

        except Exception as e:
            report_data.append(f"ä¾†æº: {source}\nç‹€æ…‹: âŒ å ±éŒ¯ ({str(e)})\n{'-'*50}")
            print(f"    âŒ éŒ¯èª¤: {e}")

    # å¯«å…¥å ±å‘Šæª”æ¡ˆï¼Œæ–¹ä¾¿ä½ ä¹‹å¾Œ check è¿”é‚Šå•² Source ä¿‚å»¢å˜…
    with open("source_report.txt", "w", encoding="utf-8") as f:
        f.write(f"IPTV ä¾†æºå¥åº·åº¦åˆ†æå ±å‘Š\nç”Ÿæˆæ™‚é–“: {datetime.datetime.now()}\n{'='*50}\n")
        f.write("\n".join(report_data))
            
    return all_valid_channels

def generate_m3u(valid_channels):
    """
    ã€åŠŸèƒ½ã€‘æœ€å¾Œç”Ÿæˆï¼šå°‡çµæœæŒ‰ç…§ã€Œåˆ†çµ„ã€åŠã€Œé€Ÿåº¦ã€æ’å¥½ï¼Œè¼¸å‡º M3U
    - æ’åºé‡é»ï¼šå¤§åˆ†çµ„ (é¦™æ¸¯/å»£æ±/å°ç£) -> é »é“æ’å (ç¿¡ç¿ å°å…ˆã€J2å¾Œ) -> é€Ÿåº¦ (å¿«å˜…æ’å…ˆ)
    """
    final_list = list(STATIC_CHANNELS)
    final_list.extend(valid_channels)

    print(f"\nğŸ”„ æ­£åœ¨é€²è¡Œæ¬Šé‡æ’åº (ç¸½æ•¸: {len(final_list)})...", flush=True)
    # åˆ©ç”¨ get_sort_key è¿”å›çš„æ•¸å€¼é€²è¡Œå‡åºæ’åº (ç´°æ•¸è¡Œå…ˆ)
    final_list.sort(key=get_sort_key)

    content = '#EXTM3U x-tvg-url="https://epg.112114.xyz/pp.xml"\n'
    content += f'# Update: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n'

    # åˆ†çµ„è¼¸å‡ºé‚è¼¯
    groups = ["å»£æ±/å»£å·", "é¦™æ¸¯", "å°ç£", "æ¾³é–€", "å…¶ä»–"]
    for current_group in groups:
        for item in final_list:
            name = item["name"]
            speed = item.get('speed', 0)
            
            # ã€åˆ†çµ„åˆ¤å®šè¦å‰‡ã€‘åŒ get_sort_key å…¥é¢å˜…é‚è¼¯è¦å°æ‡‰
            if any(x in name for x in ["æ¾³é–€", "æ¾³è¦–", "æ¾³äº", "TDM"]): ig = "æ¾³é–€"
            elif any(x in name for x in ["æ°‘è¦–", "ä¸­è¦–", "è¯è¦–", "å…¬è¦–", "TVBS", "ä¸‰ç«‹", "æ±æ£®", "å¹´ä»£", "ç·¯ä¾†", "ä¸­å¤©", "éå‡¡"]): ig = "å°ç£"
            elif any(x in name for x in ["å»£å·", "å»£æ±", "ç æ±Ÿ", "å¤§ç£å€", "å—æ–¹"]): ig = "å»£æ±/å»£å·"
            elif any(x in name for x in ["ç¿¡ç¿ ", "ç„¡ç·š", "æ˜ç ", "æ¸¯å°", "RTHK", "viu", "HOY", "å¥‡å¦™", "æœ‰ç·š", "Now", "J2", "J5"]): ig = "é¦™æ¸¯"
            else: ig = "å…¶ä»–"

            if ig == current_group:
                # å¯«å…¥ M3U æª”æ¡ˆï¼Œæ¨™è¨»åŸ‹æ¸¬é€Ÿçµæœ (ms) æ–¹ä¾¿é™¤éŒ¯
                content += f'#EXTINF:-1 group-title="{ig}" logo="https://epg.112114.xyz/logo/{name}.png",{name} ({speed}ms)\n{item["url"]}\n'

    with open("hk_live.m3u", "w", encoding="utf-8") as f:
        f.write(content)
    print(f"\nğŸ‰ å¤§åŠŸå‘Šæˆï¼æª”æ¡ˆå·²å„²å­˜ç‚º hk_live.m3u", flush=True)

def get_sort_key(item):
    """
    ã€åŠŸèƒ½ã€‘æ¬Šé‡è¨ˆç®—æ³• (æ’åºæ ¸å¿ƒ)
    - gp (Group Point): å¤§åˆ†é¡ï¼Œå»£æ±(100) < é¦™æ¸¯(200) < å°ç£(300) ...
    - kp (Keyword Point): å°åå„ªå…ˆç´šï¼ŒORDER_KEYWORDS å…¥é¢æ„ˆå‰å˜…æ„ˆç´°åˆ†ã€‚
    - speed å¾®èª¿: å°‡ speed é™¤ä»¥ 1,000,000ï¼Œç¢ºä¿å””æœƒå½±éŸ¿ gp åŒ kpï¼Œä½†å–ºåŒä¸€å€‹å°å˜…æ™‚å€™ï¼Œå¿«å˜…æ’å…ˆã€‚
    """
    name = item["name"]
    speed = item.get('speed', 9999)

    # 1. æ±ºå®šå¤§åˆ†çµ„æ¬Šé‡
    if any(x in name for x in ["å»£å·", "å»£æ±", "ç æ±Ÿ", "å¤§ç£å€", "å—æ–¹"]): gp = 100
    elif any(x in name for x in ["ç¿¡ç¿ ", "ç„¡ç·š", "æ˜ç ", "æ¸¯å°", "RTHK", "viu", "HOY", "å¥‡å¦™", "æœ‰ç·š", "Now", "J2", "J5"]): gp = 200
    elif any(x in name for x in ["æ°‘è¦–", "ä¸­è¦–", "è¯è¦–", "å…¬è¦–", "TVBS", "ä¸‰ç«‹", "æ±æ£®", "å¹´ä»£", "ç·¯ä¾†", "ä¸­å¤©", "éå‡¡"]): gp = 300
    elif any(x in name for x in ["æ¾³é–€", "æ¾³è¦–", "æ¾³äº", "TDM"]): gp = 400
    else: gp = 500

    # 2. æ±ºå®šé »é“åæ¬Šé‡ (ä¾ç…§ ORDER_KEYWORDS çš„ index)
    kp = 99
    for i, k in enumerate(ORDER_KEYWORDS):
        if k.lower() in name.lower():
            kp = i
            break
    
    # 3. é€Ÿåº¦å¾®èª¿ï¼šä¾‹å¦‚ 200ms æœƒè®Šæˆ 0.0002ï¼Œ300ms è®Šæˆ 0.0003
    return gp + kp + (speed / 1000000)

if __name__ == "__main__":
    # ç¬¬ä¸€æ­¥ï¼šåŸ·è¡Œä¸»çˆ¬èŸ²
    live_channels = fetch_and_parse()
    
    # ç¬¬äºŒæ­¥ï¼šè™•ç†æ‰‹å‹•è£œå……æº (åŒæ¨£è¦ç¶“éæ¸¬é€Ÿ)
    existing_urls = {c['url'] for c in live_channels}
    print(f"\nğŸ“¦ æ­£åœ¨æª¢æŸ¥æ‰‹å‹•è£œå……æº...", flush=True)
    for item in MANUAL_SINGLE_CHANNELS:
        item['name'] = cc.convert(item['name']).replace('è‡º', 'å°')
        if item['url'] not in existing_urls:
            checked = check_url(item)
            if checked:
                live_channels.append(checked)
                existing_urls.add(item['url'])
                print(f"    [+] æ‰‹å‹•æºæ³¨å…¥æˆåŠŸ: {item['name']} ({checked.get('speed')}ms)")
        else:
            print(f"    [!] é‡è¤‡ Linkï¼Œè·³é: {item['name']}")

    # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆæœ€çµ‚æª”æ¡ˆ
    generate_m3u(live_channels)
