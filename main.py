import requests
import re
import datetime
from opencc import OpenCC
from concurrent.futures import ThreadPoolExecutor

# ã€åˆå§‹åŒ–ã€‘ç¹ç°¡è½‰æ›å™¨ (s2t = Simplified to Traditional)
cc = OpenCC('s2t')

# --- è¨­å®šå€ ---

# 1. ç¶²è·¯è¨‚é–±æºåˆ—è¡¨ï¼šç¨‹å¼æœƒé€å€‹ç¶²å€å»çˆ¬ M3U å…§å®¹
SOURCE_URLS = [
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E5%8F%B0%E6%B9%BE%E9%A6%99%E6%B8%AF%E6%BE%B3%E9%97%A8202506.m3u",
    # ... (ä¸­é–“çœç•¥ï¼Œä¿æŒä½ åŸæœ¬å˜…ç¶²å€æ¸…å–®)
    "https://raw.githubusercontent.com/melody0709/cmcc_iptv_auto_py/main/tv2.m3u"
]

# 2. æ‰‹å‹•è£œå……æºï¼šå¦‚æœä½ æœ‰å•²ç§è—æˆ–è€…æ¯”è¼ƒç©©å®šç•ªå˜… Linkï¼Œå¯ä»¥å¯«æ­»å–ºåº¦
MANUAL_SINGLE_CHANNELS = [
    {"name": "ç¿¡ç¿ å°", "url": "https://HaNoiIPTV.short.gy/Que_huong_HaNoiIPTV-TVB_Fei_Cui_Tai"},
    # ... (ä¸­é–“çœç•¥ï¼Œä¿æŒä½ åŸæœ¬å˜…æ‰‹å‹•æ¸…å–®)
    {"name": "å¤§ç£å€è¡›è¦–", "url": "http://gmxw.7766.org:808/hls/132/index.m3u8"}
]

# 3. é—œéµå­—éæ¿¾ï¼šåå…¥é¢ä¸€å®šè¦æœ‰å‘¢å•²å­—å…ˆè‡³æœƒæ”¶éŒ„ (ç™½åå–®)
KEYWORDS = ["ViuTV", "HOY", "RTHK", "Jade", "Pearl", "J2", "J5", "Now", "æ— çº¿", "ç„¡ç·š", "æœ‰çº¿", "æœ‰ç·š", "ç¿¡ç¿ ", "æ˜ç ", "æ¸¯å°", "å»£æ±", "ç æ±Ÿ", "å¹¿å·", "å»£å·", "å¤§ç£å€","é³³å‡°", "å‡¤å‡°","æˆäºº", "æ°‘è¦–", "æ±æ£®", "ä¸‰ç«‹", "ä¸­è¦–", "å…¬è¦–", "TVBS", "ç·¯ä¾†", "å¹´ä»£", "ä¸­å¤©", "éå‡¡", "æ¾³è¦–", "æ¾³é–€", "TDM", "æ¾³äº"]

# 4. é»‘åå–®ï¼šåå…¥é¢æœ‰å‘¢å•²å­—å°±ä¸€å®šå””è¦ (å‰”é™¤ç¾åœ‹å°ã€è³¼ç‰©å°ã€æ¸¬è©¦å°ç­‰)
BLOCK_KEYWORDS = ["FOX", "Pluto", "Local", "NBC", "CBS", "ABC", "AXS", "Snowy", "Reuters", "Mirror", "ET Now", "The Now", "Right Now", "News Now", "Chopper", "Wow", "UHD", "8K", "Career", "Comics", "Movies", "CBTV","Pearl","AccuWeather","Jadeed","Curiosity","Electric", "Warfare","Knowledge","MagellanTV","70s","80s","90s","Rock", "Winnipeg","Edmonton","RightNow","Times","True","Mindanow", "æµ™æ±Ÿ", "æ­å·", "è¥¿æ¹–", "æ·±åœ³", "éŸ¶é—œ", "CCTV", "CGTN", "è¯éº—", "æ˜Ÿæ²³", "å»¶æ—¶", "æ¸¬è©¦", "iHOY", "ç¦å»º"]

# 5. æ’åºå„ªå…ˆç´šï¼šè¶Šæ’å‰é¢å˜…å­—ï¼Œå–º M3U æ’­æ”¾å™¨å…¥é¢å°±æœƒæ’å¾—è¶Šé ä¸Š
ORDER_KEYWORDS = ["å»£æ±", "ç æ±Ÿ", "å»£å·", "å»£æ±è¡›è¦–", "å¤§ç£å€", "å—æ–¹", "æ¸¯å°é›»è¦–", "ç¿¡ç¿ ", "ç„¡ç·šæ–°è", "æ˜ç ", "J2", "J5", "è²¡ç¶“", "Viu", "HOY", "å¥‡å¦™", "æœ‰ç·š", "Now", "æ°‘è¦–", "ä¸­è¦–", "è¯è¦–", "å…¬è¦–", "TVBS", "ä¸‰ç«‹", "æ±æ£®", "å¹´ä»£", "å£¹é›»è¦–", "éå‡¡", "ä¸­å¤©", "ç·¯ä¾†", "æ¾³è¦–", "æ¾³é–€", "TDM", "æ¾³äº"]

# 6. éœæ…‹æºï¼šçµ•å°ç©©å®šã€å””ä½¿ check å˜…å®˜æ–¹ Link
STATIC_CHANNELS = [
    {"name": "æ¸¯å°é›»è¦–31 (å®˜æ–¹)", "url": "https://rthklive1-lh.akamaihd.net/i/rthk31_1@167495/index_2052_av-b.m3u8"},
    {"name": "æ¸¯å°é›»è¦–32 (å®˜æ–¹)", "url": "https://rthklive2-lh.akamaihd.net/i/rthk32_1@168450/index_2052_av-b.m3u8"}
]

# --- æ ¸å¿ƒé‚è¼¯å€ ---

def check_url(item):
    """
    ã€åŠŸèƒ½ã€‘æª¢æŸ¥å–®å€‹ç¶²å€ä¿‚å’ªä»²è¡Œå¾—é€š
    1. å…ˆè©¦ HEAD (æ·¨ä¿‚è®€ Headerï¼Œå¿«å•²)
    2. å¦‚æœ HEAD å””å¾—å°±è©¦ GET (åªè®€é–‹é ­)
    """
    url = item['url']
    headers = {'User-Agent': 'Mozilla/5.0...', 'Referer': url}
    try:
        # allow_redirects=True è™•ç†è·³è½‰ Link
        response = requests.head(url, timeout=2, headers=headers, allow_redirects=True)
        if response.status_code == 200: return item
        
        # æŸå•²æºé˜»æ“‹ HEADï¼Œè¦ç”¨ GET stream æ¨¡å¼
        response = requests.get(url, timeout=3, headers=headers, stream=True)
        if response.status_code == 200:
            response.close() # é€šå’—å°±æ–·é–‹ï¼Œæ…³æµé‡
            return item
    except: pass
    return None

def fetch_and_parse():
    """
    ã€åŠŸèƒ½ã€‘éæ­· SOURCE_URLSï¼Œä¸‹è¼‰ M3U å…§å®¹ä¸¦è§£æå‡ºé »é“ååŒ URL
    """
    found_channels = []
    seen_urls = set() # ç”¨ Set åšŸåšã€Œå…¨çƒå”¯ä¸€ã€å»é‡ï¼ŒLink ä¸€æ¨£å°±å””è¦
    headers = {'User-Agent': 'Mozilla/5.0...', 'Referer': 'https://live.hacks.tools/'}
    
    print("ğŸš€ ä»»å‹™é–‹å§‹ï¼æ­£åœ¨æŠ“å–ç¶²è·¯æº...", flush=True)
    
    for index, source in enumerate(SOURCE_URLS):
        print(f"  [{index+1}/{len(SOURCE_URLS)}] æ­£åœ¨è®€å–: {source}", flush=True)
        is_taiwan_source = "tw.m3u" in source.lower() # æ¨™è¨˜ä¿‚å’ªå°ç£å°ˆå±¬æº
        try:
            r = requests.get(source, timeout=15, headers=headers)
            r.encoding = 'utf-8'
            if r.status_code != 200: continue
            
            lines = r.text.split('\n')
            current_name, count_added = "", 0
            for line in lines:
                line = line.strip()
                if not line: continue
                # æ”é »é“å
                if line.startswith("#EXTINF"):
                    if ',' in line:
                        raw_name = line.split(',')[-1].strip()
                        current_name = cc.convert(raw_name).replace('è‡º', 'å°')
                # æ”ç¶²å€ä¸¦éæ¿¾
                elif line.startswith("http") and current_name:
                    if "[" in line and "]" in line: continue # é£›èµ° IPv6
                    if any(b.lower() in current_name.lower() for b in BLOCK_KEYWORDS): continue # é»‘åå–®
                    
                    is_match = any(cc.convert(k).replace('è‡º', 'å°').lower() in current_name.lower() for k in KEYWORDS)
                    # ç¬¦åˆç™½åå–®é—œéµå­—ï¼Œæˆ–è€…ä¿‚å°ç£å°ˆå±¬æºï¼Œå…ˆè‡³æ”¶éŒ„
                    if is_match or is_taiwan_source:
                        if line not in seen_urls:
                            found_channels.append({"name": current_name, "url": line})
                            seen_urls.add(line)
                            count_added += 1
                    current_name = ""
            print(f"    âœ… æŠ“å–æˆåŠŸï¼Œæ–°å¢ {count_added} å€‹é »é“", flush=True)
        except Exception as e:
            print(f"    âŒ æŠ“å–éŒ¯èª¤: {e}", flush=True)
    return found_channels

def generate_m3u(channels):
    """
    ã€åŠŸèƒ½ã€‘æª¢æ¸¬æœ‰æ•ˆæ€§ã€æ’åºã€ä¸¦ç”Ÿæˆæœ€çµ‚ M3U æª”æ¡ˆ
    """
    print(f"\nğŸ” å…±æ‰¾åˆ° {len(channels)} å€‹æ½›åœ¨é »é“ï¼Œé–‹å§‹æª¢æ¸¬æœ‰æ•ˆæ€§...", flush=True)
    final_list = list(STATIC_CHANNELS) # å…ˆæ”¾å…¥å®˜æ–¹æº
    
    # ã€å¤šç·šç¨‹ã€‘20 æ¢ç·šç¨‹åŒæ™‚é–‹å·¥ Check Linkï¼Œå””ä½¿ä¸€æ¢ä¸€æ¢ç­‰
    print(f"âš¡ å•Ÿå‹•å¤šç·šç¨‹æª¢æ¸¬ (20 ç·šç¨‹åŒæ­¥é€²è¡Œ)...", flush=True)
    with ThreadPoolExecutor(max_workers=20) as executor:
        results = list(executor.map(check_url, channels))
    
    # éæ¿¾å‡ºæˆåŠŸå˜…çµæœ
    valid_channels = [r for r in results if r is not None]
    valid_urls = {r['url'] for r in valid_channels}
    
    # é¡¯ç¤ºæ­»éˆ (Log è¼¸å‡º)
    invalid_channels = [c for c in channels if c['url'] not in valid_urls]
    if invalid_channels:
        print(f"\nğŸš« æª¢æ¸¬åˆ° {len(invalid_channels)} å€‹å¤±æ•ˆé€£çµï¼š")
        for ch in invalid_channels:
            print(f"  [X] æ­»éˆ: {ch['name']} - {ch['url']}")

    final_list.extend(valid_channels)
    print(f"\nâœ… æª¢æ¸¬å®Œæˆï¼å…±æ”¶éŒ„ {len(valid_channels)} å€‹æœ‰æ•ˆç¶²è·¯é »é“ã€‚", flush=True)

    # æ’åº
    print("ğŸ”„ æ­£åœ¨é€²è¡Œæ’åº...", flush=True)
    final_list.sort(key=get_sort_key)

    # ã€å¯«å…¥æª”æ¡ˆã€‘ç”Ÿæˆç¬¦åˆæ¨™æº–å˜… M3U æ ¼å¼
    content = '#EXTM3U x-tvg-url="https://epg.112114.xyz/pp.xml"\n'
    content += f'# Update: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n'
    
    # åˆ†çµ„å¯«å…¥é‚è¼¯
    groups = ["å»£æ±/å»£å·", "é¦™æ¸¯", "å°ç£", "æ¾³é–€", "å…¶ä»–"]
    for current_group in groups:
        for item in final_list:
            name = item["name"].replace('è‡º', 'å°')
            # æ ¹æ“šé—œéµå­—æ±ºå®š group-title
            if any(x in name for x in ["æ¾³é–€", "æ¾³è¦–", "æ¾³äº", "TDM"]): ig = "æ¾³é–€"
            elif any(x in name for x in ["æ°‘è¦–", "ä¸­è¦–", "è¯è¦–", "å…¬è¦–", "TVBS", "ä¸‰ç«‹", "æ±æ£®", "å¹´ä»£", "ç·¯ä¾†", "ä¸­å¤©", "éå‡¡"]): ig = "å°ç£"
            elif any(x in name for x in ["å»£å·", "å»£æ±", "ç æ±Ÿ", "å¤§ç£å€", "å—æ–¹"]): ig = "å»£æ±/å»£å·"
            elif any(x in name for x in ["ç¿¡ç¿ ", "ç„¡ç·š", "æ˜ç ", "æ¸¯å°", "RTHK", "Viu", "HOY", "å¥‡å¦™", "æœ‰ç·š", "Now", "J2", "J5"]): ig = "é¦™æ¸¯"
            else: ig = "å…¶ä»–"

            if ig == current_group:
                # å¯«å…¥ Logo ç¶²å€åŒé »é“è³‡æ–™
                content += f'#EXTINF:-1 group-title="{ig}" logo="https://epg.112114.xyz/logo/{name}.png",{name}\n{item["url"]}\n'

    with open("hk_live.m3u", "w", encoding="utf-8") as f:
        f.write(content)
    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼å…±ç”Ÿæˆ {len(final_list)} å€‹é »é“ã€‚", flush=True)

def get_sort_key(item):
    """
    ã€åŠŸèƒ½ã€‘è¨ˆç®—æ’åºæ¬Šé‡ã€‚æ•¸å­—è¶Šç´°æ’è¶Šå…ˆã€‚
    """
    name = item["name"]
    # 1. æ±ºå®šå¤§çµ„å„ªå…ˆç´š
    if any(x in name for x in ["å»£å·", "å»£æ±", "ç æ±Ÿ", "å¤§ç£å€", "å—æ–¹"]): gp = 100
    elif any(x in name for x in ["ç¿¡ç¿ ", "ç„¡ç·š", "æ˜ç ", "æ¸¯å°", "RTHK", "Viu", "HOY", "å¥‡å¦™", "æœ‰ç·š", "Now", "J2", "J5"]): gp = 200
    elif any(x in name for x in ["æ°‘è¦–", "ä¸­è¦–", "è¯è¦–", "å…¬è¦–", "TVBS", "ä¸‰ç«‹", "æ±æ£®", "å¹´ä»£", "ç·¯ä¾†", "ä¸­å¤©", "éå‡¡"]): gp = 300
    elif any(x in name for x in ["æ¾³é–€", "æ¾³è¦–", "æ¾³äº", "TDM"]): gp = 400
    else: gp = 500
    
    # 2. å–ºçµ„å…§æ ¹æ“š ORDER_KEYWORDS ç´°åˆ†å„ªå…ˆç´š
    kp = 99
    for i, k in enumerate(ORDER_KEYWORDS):
        if k.lower() in name.lower():
            kp = i
            break
    return gp + kp

# --- ç¨‹å¼å…¥å£ ---
if __name__ == "__main__":
    # ç¬¬ä¸€æ­¥ï¼šçˆ¬å–ç¶²è·¯æº
    candidates = fetch_and_parse()
    
    # æ”å‡ºæ‰€æœ‰å·²ç¶“çˆ¬åˆ°å˜… URL åšå°æ¯”
    existing_urls = {c['url'] for c in candidates}
    
    # ç¬¬äºŒæ­¥ï¼šæ³¨å…¥æ‰‹å‹•æº (æª¢æŸ¥ä¿‚å’ªé‡è¤‡)
    print(f"\nğŸ“¦ æ­£åœ¨æ³¨å…¥æ‰‹å‹•æº...", flush=True)
    for item in MANUAL_SINGLE_CHANNELS:
        item['name'] = cc.convert(item['name']).replace('è‡º', 'å°')
        if item['url'] not in existing_urls:
            print(f"  [+] æ³¨å…¥æˆåŠŸ: {item['name']}")
            candidates.append(item)
            existing_urls.add(item['url'])
        else:
            print(f"  [!] æ‰‹å‹•æºå·²å­˜åœ¨ï¼Œè·³é: {item['name']} ({item['url']})")
    
    # ç¬¬ä¸‰æ­¥ï¼šæ ¡é©—ä¸¦ç”Ÿæˆæª”æ¡ˆ
    generate_m3u(candidates)
